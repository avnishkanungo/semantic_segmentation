{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0658506a-ad8d-40e0-9e02-da5771ebce32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import torch\n",
    "import torchvision.transforms as tvt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import glob\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as tvt\n",
    "from torchvision import utils\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import time\n",
    "import skimage.io as io\n",
    "from pycocotools.coco import COCO\n",
    "import numpy as np\n",
    "import copy\n",
    "from scipy.ndimage import zoom\n",
    "import torch.optim as optim\n",
    "from DLStudio import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6846a6f7-3e4b-463b-aad8-83ca4e05561c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ann = COCO('/Users/avnishkanungo/Desktop/coco-dataset/train2017/train2017/annotations/instances_train2017.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1a54cb-4b9f-4ff2-8908-bbd781eb8a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ann = COCO('/Users/avnishkanungo/Desktop/coco-dataset/train2017/train2017/annotations/instances_val2017.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f918da14-f829-414f-a70a-8597358e323f",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_directory_train = '/Users/avnishkanungo/Desktop/coco-dataset/train2017/train2017/train2017'\n",
    "root_directory_test = '/Users/avnishkanungo/Desktop/coco-dataset/train2017/train2017/val2017'\n",
    "classes = ['cake', 'dog', 'motorcycle']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37228c52-cddc-4e7e-8455-04767b795a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getImgAndMask(coco, path, classes):\n",
    "    l = coco.getImgIds() #list(coco.imgs.keys())\n",
    "    masks = []\n",
    "    img = []\n",
    "    class_ids = [coco.getCatIds(catNms=[class_name])[0] for class_name in classes]\n",
    "    for i in l:\n",
    "        x = coco.getAnnIds(i)\n",
    "        y = coco.loadAnns(x)\n",
    "        if y:\n",
    "            if y[0]['category_id'] in class_ids:\n",
    "                image_info = coco.loadImgs(i)[0]\n",
    "                mask = np.zeros((image_info[\"height\"], image_info[\"width\"]), dtype=np.uint8)\n",
    "                \n",
    "                if len(y) == 1:\n",
    "                        bbox = y[0]['bbox']\n",
    "                        bbox_size = max(bbox[2], bbox[3])\n",
    "                    \n",
    "                        if bbox_size >= 200:\n",
    "                            image_path = f\"{path}/{image_info['file_name']}\"\n",
    "                            image = Image.open(image_path).convert(\"RGB\")\n",
    "                            image = image.resize((256,256))\n",
    "                            img.append(image)\n",
    "                            \n",
    "                            for ann in y:\n",
    "                                mask += coco.annToMask(ann)\n",
    "                                mask = zoom(mask, (256/image_info[\"height\"], 256/image_info[\"width\"]), order=1)\n",
    "                                masks.append(mask)\n",
    "\n",
    "    return masks, img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f52736-368e-4ffe-bae2-3a8c91c55c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomCocoDataset(Dataset):\n",
    "    def __init__(self, masks, images, transform=None):\n",
    "        self.masks = masks\n",
    "        self.images = images\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.masks)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        mask = self.masks[idx]\n",
    "        image = self.images[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            \n",
    "            mask = torch.tensor(mask, dtype=torch.float32)\n",
    "            image, transformed_mask = self.transform(image, mask)\n",
    "\n",
    "        return transformed_mask, image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e7f7c7-60b6-44ad-b884-6df2091921bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTransform:\n",
    "    def __init__(self, image_transforms):\n",
    "        self.image_transforms = image_transforms\n",
    "\n",
    "    def __call__(self, image, mask):\n",
    "        transformed_image = self.image_transforms(image)\n",
    "        transformed_mask = torch.unsqueeze(mask, 0)  # Add channel dimension\n",
    "        return transformed_image, transformed_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc18715f-3120-4916-9320-9e9ed688e289",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_transform = tvt.Compose([\n",
    "    tvt.ToTensor(),\n",
    "    tvt.Resize(size=(256,256))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f533a5eb-c68a-4960-91ef-cb2c30f41ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = CustomTransform(image_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa48163-85a6-4369-8d61-bcff2062b061",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = CustomCocoDataset(im_masks_test, im_img_test, transform=transform)\n",
    "train_dataset = CustomCocoDataset(im_masks_train, im_img_train, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4eb9d6-a039-4458-a2b8-b8d4f202e0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = DataLoader(test_dataset, batch_size=4, shuffle=True)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=4, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555d159c-03ed-47d3-b036-40bd76d24377",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SkipBlockDN(nn.Module):\n",
    "                \n",
    "                def __init__(self, in_ch, out_ch, downsample=False, skip_connections=True):\n",
    "                    super(SkipBlockDN, self).__init__()\n",
    "                    self.downsample = downsample\n",
    "                    self.skip_connections = skip_connections\n",
    "                    self.in_ch = in_ch\n",
    "                    self.out_ch = out_ch\n",
    "                    self.convo1 = nn.Conv2d(in_ch, out_ch, 3, stride=1, padding=1)\n",
    "                    self.convo2 = nn.Conv2d(in_ch, out_ch, 3, stride=1, padding=1)\n",
    "                    self.bn1 = nn.BatchNorm2d(out_ch)\n",
    "                    self.bn2 = nn.BatchNorm2d(out_ch)\n",
    "                    if downsample:\n",
    "                        self.downsampler = nn.Conv2d(in_ch, out_ch, 1, stride=2)\n",
    "                def forward(self, x):\n",
    "                    identity = x                                     \n",
    "                    out = self.convo1(x)                              \n",
    "                    out = self.bn1(out)                              \n",
    "                    out = nn.functional.relu(out)\n",
    "                    if self.in_ch == self.out_ch:\n",
    "                        out = self.convo2(out)                              \n",
    "                        out = self.bn2(out)                              \n",
    "                        out = nn.functional.relu(out)\n",
    "                    if self.downsample:\n",
    "                        out = self.downsampler(out)\n",
    "                        identity = self.downsampler(identity)\n",
    "                    if self.skip_connections:\n",
    "                        if self.in_ch == self.out_ch:\n",
    "                            out = out + identity\n",
    "                        else:\n",
    "                            out = out + torch.cat((identity, identity), dim=1) \n",
    "                    return out\n",
    "    \n",
    "    \n",
    "class SkipBlockUP(nn.Module):\n",
    "                \n",
    "                def __init__(self, in_ch, out_ch, upsample=False, skip_connections=True):\n",
    "                    super(SkipBlockUP, self).__init__()\n",
    "                    self.upsample = upsample\n",
    "                    self.skip_connections = skip_connections\n",
    "                    self.in_ch = in_ch\n",
    "                    self.out_ch = out_ch\n",
    "                    self.convoT1 = nn.ConvTranspose2d(in_ch, out_ch, 3, padding=1)\n",
    "                    self.convoT2 = nn.ConvTranspose2d(in_ch, out_ch, 3, padding=1)\n",
    "                    self.bn1 = nn.BatchNorm2d(out_ch)\n",
    "                    self.bn2 = nn.BatchNorm2d(out_ch)\n",
    "                    if upsample:\n",
    "                        self.upsampler = nn.ConvTranspose2d(in_ch, out_ch, 1, stride=2, dilation=2, output_padding=1, padding=0)\n",
    "                def forward(self, x):\n",
    "                    identity = x                                     \n",
    "                    out = self.convoT1(x)                              \n",
    "                    out = self.bn1(out)                              \n",
    "                    out = nn.functional.relu(out)\n",
    "                    out  =  nn.ReLU(inplace=False)(out)            \n",
    "                    if self.in_ch == self.out_ch:\n",
    "                        out = self.convoT2(out)                              \n",
    "                        out = self.bn2(out)                              \n",
    "                        out = nn.functional.relu(out)\n",
    "                    if self.upsample:\n",
    "                        out = self.upsampler(out)\n",
    "                        identity = self.upsampler(identity)\n",
    "                    if self.skip_connections:\n",
    "                        if self.in_ch == self.out_ch:\n",
    "                            out = out + identity                              \n",
    "                        else:\n",
    "                            out = out + identity[:,self.out_ch:,:,:]\n",
    "                    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934a64fb-d24c-48f0-af90-0284859bfbb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class mUnet(nn.Module):\n",
    "               \n",
    "    def __init__(self, skip_connections=True, depth=16):\n",
    "                    super(mUnet, self).__init__()\n",
    "                    self.depth = depth // 2\n",
    "                    self.conv_in = nn.Conv2d(3, 64, 3, padding=1)\n",
    "                    ##  For the DN arm of the U:\n",
    "                    self.bn1DN  = nn.BatchNorm2d(64)\n",
    "                    self.bn2DN  = nn.BatchNorm2d(128)\n",
    "                    self.skip64DN_arr = nn.ModuleList()\n",
    "                    for i in range(self.depth):\n",
    "                        self.skip64DN_arr.append(SkipBlockDN(64, 64, skip_connections=skip_connections))\n",
    "                    self.skip64dsDN = SkipBlockDN(64, 64,   downsample=True, skip_connections=skip_connections)\n",
    "                    self.skip64to128DN = SkipBlockDN(64, 128, skip_connections=skip_connections )\n",
    "                    self.skip128DN_arr = nn.ModuleList()\n",
    "                    for i in range(self.depth):\n",
    "                        self.skip128DN_arr.append(SkipBlockDN(128, 128, skip_connections=skip_connections))\n",
    "                    self.skip128dsDN = SkipBlockDN(128,128, downsample=True, skip_connections=skip_connections)\n",
    "                    ##  For the UP arm of the U:\n",
    "                    self.bn1UP  = nn.BatchNorm2d(128)\n",
    "                    self.bn2UP  = nn.BatchNorm2d(64)\n",
    "                    self.skip64UP_arr = nn.ModuleList()\n",
    "                    for i in range(self.depth):\n",
    "                        self.skip64UP_arr.append(SkipBlockUP(64, 64, skip_connections=skip_connections))\n",
    "                    self.skip64usUP = SkipBlockUP(64, 64, upsample=True, skip_connections=skip_connections)\n",
    "                    self.skip128to64UP = SkipBlockUP(128, 64, skip_connections=skip_connections )\n",
    "                    self.skip128UP_arr = nn.ModuleList()\n",
    "                    for i in range(self.depth):\n",
    "                        self.skip128UP_arr.append(SkipBlockUP(128, 128, skip_connections=skip_connections))\n",
    "                    self.skip128usUP = SkipBlockUP(128,128, upsample=True, skip_connections=skip_connections)\n",
    "                    self.conv_out = nn.ConvTranspose2d(64, 1, 3, stride=2,dilation=2,output_padding=1,padding=2) #remember to change the output channel to 3 later\n",
    "    \n",
    "    def forward(self, x):\n",
    "                    ##  Going down to the bottom of the U:\n",
    "                    x = nn.MaxPool2d(2,2)(nn.functional.relu(self.conv_in(x)))          \n",
    "                    for i,skip64 in enumerate(self.skip64DN_arr[:self.depth//4]):\n",
    "                        x = skip64(x)                \n",
    "            \n",
    "                    num_channels_to_save1 = x.shape[1] // 2\n",
    "                    save_for_upside_1 = x[:,:num_channels_to_save1,:,:].clone()\n",
    "                    x = self.skip64dsDN(x)\n",
    "                    for i,skip64 in enumerate(self.skip64DN_arr[self.depth//4:]):\n",
    "                        x = skip64(x)                \n",
    "                    x = self.bn1DN(x)\n",
    "                    num_channels_to_save2 = x.shape[1] // 2\n",
    "                    save_for_upside_2 = x[:,:num_channels_to_save2,:,:].clone()\n",
    "                    x = self.skip64to128DN(x)\n",
    "                    for i,skip128 in enumerate(self.skip128DN_arr[:self.depth//4]):\n",
    "                        x = skip128(x)                \n",
    "            \n",
    "                    x = self.bn2DN(x)\n",
    "                    num_channels_to_save3 = x.shape[1] // 2\n",
    "                    save_for_upside_3 = x[:,:num_channels_to_save3,:,:].clone()\n",
    "                    for i,skip128 in enumerate(self.skip128DN_arr[self.depth//4:]):\n",
    "                        x = skip128(x)                \n",
    "                    x = self.skip128dsDN(x)\n",
    "                    ## Coming up from the bottom of U on the other side:\n",
    "                    x = self.skip128usUP(x)          \n",
    "                    for i,skip128 in enumerate(self.skip128UP_arr[:self.depth//4]):\n",
    "                        x = skip128(x)                \n",
    "                    x[:,:num_channels_to_save3,:,:] =  save_for_upside_3\n",
    "                    x = self.bn1UP(x)\n",
    "                    for i,skip128 in enumerate(self.skip128UP_arr[:self.depth//4]):\n",
    "                        x = skip128(x)                \n",
    "                    x = self.skip128to64UP(x)\n",
    "                    for i,skip64 in enumerate(self.skip64UP_arr[self.depth//4:]):\n",
    "                        x = skip64(x)                \n",
    "                    x[:,:num_channels_to_save2,:,:] =  save_for_upside_2\n",
    "                    x = self.bn2UP(x)\n",
    "                    x = self.skip64usUP(x)\n",
    "                    for i,skip64 in enumerate(self.skip64UP_arr[:self.depth//4]):\n",
    "                        x = skip64(x)                \n",
    "                    x[:,:num_channels_to_save1,:,:] =  save_for_upside_1\n",
    "                    x = self.conv_out(x)\n",
    "                    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ca9be0-1c61-4b5f-98ef-84ce739e86e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MSEPlusDiceLoss1(nn.Module):\n",
    "    def __init__(self, alpha=0.5, epsilon=1e-2):\n",
    "        super(MSEPlusDiceLoss1, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "    def forward(self, output, mask_tensor):\n",
    "        total_loss = 0\n",
    "        composite_loss = torch.zeros(1, 4, requires_grad=True)\n",
    "        dice_loss = torch.zeros(1, 4, requires_grad=True)\n",
    "        mse_loss = torch.zeros(1, 4, requires_grad=True)\n",
    "\n",
    "        for idx in range(min(output.shape[0], mask_tensor.shape[0])):\n",
    "            mask = mask_tensor[idx, 0, :, :]\n",
    "            output_mask = output[idx, 0, :, :]\n",
    "\n",
    "            # Dice Loss\n",
    "            if torch.sum(mask)+torch.sum(output_mask)>0:\n",
    "                intersection = torch.sum(output_mask * mask)\n",
    "                union = torch.sum(output_mask) + torch.sum(mask) + self.epsilon\n",
    "                dice_coefficient = (2. * intersection + self.epsilon) / union\n",
    "                dice_loss_copy = dice_loss.clone()\n",
    "                dice_loss_copy[0,idx] = 1 - dice_coefficient\n",
    "                dice_loss = dice_loss_copy\n",
    "\n",
    "            if torch.sum(mask)>0 and torch.sum(output_mask)>0:\n",
    "                # MSE Loss\n",
    "                mse_loss_copy = mse_loss.clone()\n",
    "                mse_loss_copy[0, idx] = F.mse_loss(output[idx], mask_tensor[idx])\n",
    "                mse_loss = mse_loss_copy\n",
    "\n",
    "            if torch.sum(mse_loss)>0 and torch.sum(dice_loss)>0:\n",
    "                # Composite Loss\n",
    "                composite_loss_copy = composite_loss.clone()\n",
    "                composite_loss_copy[0, idx]= torch.sum(mse_loss) + 30*torch.sum(dice_loss)\n",
    "                composite_loss = composite_loss_copy\n",
    "                \n",
    "        average_loss = torch.sum(composite_loss) / min(output.shape[0], mask_tensor.shape[0])\n",
    "        \n",
    "        return average_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ae0f4d-17d0-455c-bdc1-f97274aa9b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_code_for_training_for_semantic_segmentation(net, data_loader):        \n",
    "                net = copy.deepcopy(net)\n",
    "                net = net.to(torch.device(\"cpu\"))\n",
    "                criterion1 = MSEPlusDiceLoss1(4, alpha=0.5, epsilon = 1e-3)\n",
    "                optimizer = optim.SGD(net.parameters(), \n",
    "                             lr=1e-4, momentum=0.9)\n",
    "                start_time = time.perf_counter()\n",
    "                running_loss = []\n",
    "                for epoch in range(10):  \n",
    "                    print(\"\")\n",
    "                    running_loss_segmentation = 0.0\n",
    "                    for i, data in enumerate(data_loader):    \n",
    "                        mask_tensor, im_tensor = data\n",
    "                        # print(im_tensor.shape)\n",
    "                        im_tensor   = im_tensor.to(torch.device(\"cpu\"))\n",
    "                        mask_tensor = mask_tensor.to(torch.device(\"cpu\"))\n",
    "                        mask_tensor = mask_tensor.type(torch.FloatTensor)\n",
    "                        optimizer.zero_grad()\n",
    "                        output = net(im_tensor) \n",
    "                        segmentation_loss= criterion1(output, mask_tensor)\n",
    "                        segmentation_loss.requires_grad\n",
    "                        output.requires_grad\n",
    "                        im_tensor.requires_grad = True\n",
    "                        mask_tensor.requires_grad = True \n",
    "                        segmentation_loss.backward()\n",
    "                        optimizer.step()\n",
    "                        running_loss_segmentation += segmentation_loss.item()    \n",
    "                        if i%100==99:    \n",
    "                            current_time = time.perf_counter()\n",
    "                            elapsed_time = current_time - start_time\n",
    "                            avg_loss_segmentation = running_loss_segmentation / float(100)\n",
    "                            print(\"[epoch=%d/%d, iter=%4d  elapsed_time=%3d secs]   Combined loss: %f\" % (epoch+1, 10, i+1, elapsed_time, avg_loss_segmentation ))\n",
    "                            running_loss.append(avg_loss_segmentation)\n",
    "                            running_loss_segmentation = 0.0\n",
    "                print(\"\\nFinished Training\\n\")\n",
    "                return running_loss\n",
    "                torch.save(net.state_dict(), '/Users/avnishkanungo/Desktop/coco-dataset/train2017/hw7_model_save/save_model_loss_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d972eb5c-d3c7-4e80-a1a8-d46b3ecc1f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_code_for_testing_semantic_segmentation( net, dataloader, path):\n",
    "                net.load_state_dict(torch.load(path))\n",
    "                batch_size = 4\n",
    "                image_size = [256,256]\n",
    "                with torch.no_grad():\n",
    "                    for i, data in enumerate(dataloader):\n",
    "                        mask_tensor,im_tensor = data\n",
    "                        outputs = net(im_tensor)\n",
    "                        fig = plt.figure(figsize=(10, 7)) \n",
    "  \n",
    "                        # setting values to rows and column variables \n",
    "                        rows = 2\n",
    "                        columns = 2\n",
    "                        \n",
    "                        fig.add_subplot(rows, columns, 1) \n",
    "  \n",
    "                        # showing image \n",
    "                        plt.imshow(outputs[i-1].permute(1,2,0)) \n",
    "                        plt.axis('off') \n",
    "                        plt.title(\"Input Image\") \n",
    "                          \n",
    "                        # Adds a subplot at the 2nd position \n",
    "                        fig.add_subplot(rows, columns, 2) \n",
    "                          \n",
    "                        # showing image \n",
    "                        plt.imshow(im_tensor[i-1].permute(1,2,0)) \n",
    "                        plt.axis('off') \n",
    "                        plt.title(\"Output Image\") \n",
    "                          \n",
    "                        # Adds a subplot at the 3rd position \n",
    "                        fig.add_subplot(rows, columns, 3) \n",
    "                          \n",
    "                        # showing image \n",
    "                        plt.imshow(mask_tensor[i-1].permute(1,2,0)) \n",
    "                        plt.axis('off') \n",
    "                        plt.title(\"Image Mask\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1143e305-62bc-4fb8-9f29-36b139d34fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = mUnet(skip_connections=True, depth=16)\n",
    "\n",
    "combined_loss = run_code_for_training_for_semantic_segmentation(model, train_dataloader, '/Users/avnishkanungo/Desktop/coco-dataset/train2017/hw7_model_save/saved_model_combined')\n",
    "\n",
    "run_code_for_testing_semantic_segmentation(model, test_dataloader, '/Users/avnishkanungo/Desktop/coco-dataset/train2017/hw7_model_save/saved_model_combined')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
